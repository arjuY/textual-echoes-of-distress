{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Reddit Data Collection using Pushift Reddit API\n",
        "\n",
        "Please not that Pushift access to reddit has been rovoked in may 2023 is the code will no longer return the posts"
      ],
      "metadata": {
        "id": "EURHqB2a1CVY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKYS9Uwz4N0m",
        "outputId": "75159810-7ec2-412f-d699-f1b165141749"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pmaw\n",
            "  Downloading pmaw-3.0.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pmaw) (2.31.0)\n",
            "Collecting praw (from pmaw)\n",
            "  Downloading praw-7.7.1-py3-none-any.whl (191 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.0/191.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prawcore<3,>=2.1 (from praw->pmaw)\n",
            "  Downloading prawcore-2.3.0-py3-none-any.whl (16 kB)\n",
            "Collecting update-checker>=0.18 (from praw->pmaw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw->pmaw) (1.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pmaw) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pmaw) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pmaw) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pmaw) (2023.7.22)\n",
            "Installing collected packages: update-checker, prawcore, praw, pmaw\n",
            "Successfully installed pmaw-3.0.0 praw-7.7.1 prawcore-2.3.0 update-checker-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pmaw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS7j9rfpwl-g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pmaw import PushshiftAPI\n",
        "from datetime import datetime as dt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJU5vp45CBNd"
      },
      "outputs": [],
      "source": [
        "# Initialize PushShift\n",
        "api = PushshiftAPI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BF3nf9_xu4q"
      },
      "outputs": [],
      "source": [
        "start_epoch=int(dt(2016, 1, 1).timestamp())\n",
        "end_epoch=int(dt(2022, 1, 1).timestamp())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "achdBfQna_V_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25591fdf-9d15-4cf1-8de7-a4e3c33ba635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pmaw.PushshiftAPIBase:Not all PushShift shards are active. Query results may be incomplete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index([], dtype='object')\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "# api_request_generator = api.search_submissions(subreddit='depression',after = start_epoch, before = end_epoch)\n",
        "# #api_request_generator = api.search_submissions(subreddit='mentalillness',after = start_epoch, before = start_epoch+258600)\n",
        "# posts_df = pd.DataFrame(api_request_generator)\n",
        "# print(posts_df.columns)\n",
        "# cols_req = ['author', 'date', 'title', 'selftext','permalink', 'subreddit', 'score', 'num_comments','over_18', 'num_crossposts']\n",
        "# cols_present = [col for col in cols_req if col in posts_df]\n",
        "# print(cols_present)\n",
        "# posts_df = posts_df[cols_present]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while start_epoch < end_epoch + 2586000:\n",
        "  api_request_generator = api.search_submissions(subreddit='depression',after = start_epoch, before = start_epoch+2586000)\n",
        "  posts_df = pd.DataFrame(api_request_generator)\n",
        "  start_date = dt.fromtimestamp(start_epoch)\n",
        "  dateStr = start_date.strftime(\"%Y %b %d\")\n",
        "  print(dateStr)\n",
        "  print(posts_df.columns)\n",
        "  if not posts_df.empty:\n",
        "    posts_df['date'] = pd.to_datetime(posts_df['created_utc'], utc=True, unit='s')\n",
        "    cols_req = ['date', 'title', 'selftext','subreddit','over_18']\n",
        "    cols_present = [col for col in cols_req if col in posts_df]\n",
        "    posts_df = posts_df[cols_present]\n",
        "    start_date = dt.fromtimestamp(start_epoch)\n",
        "    dateStr = start_date.strftime(\"%Y %b %d\")\n",
        "    print(dateStr)\n",
        "\n",
        "    #posts_df.to_csv(r\"depression_posts\\sub_\" + dateStr + \".csv\", index = False, header = True)\n",
        "    posts_df.to_csv(r\"/content/drive/MyDrive/Data/r_depr\" + dateStr + \".csv\", index = False, header = True)\n",
        "\n",
        "  start_epoch += 2586000"
      ],
      "metadata": {
        "id": "kqH6hzYDeDeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/Data/M_Data\")\n",
        "extension = 'csv'\n",
        "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
        "#combine all files in the list\n",
        "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
        "#export to csv\n",
        "combined_csv.to_csv( \"/content/drive/MyDrive/dataset/reddit_posts.csv\", index=False, encoding='utf-8-sig')\n"
      ],
      "metadata": {
        "id": "W5zfmqO6iAc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_data = pd.read_csv(\"/content/drive/MyDrive/dataset/reddit_dataset.csv\")"
      ],
      "metadata": {
        "id": "D-z1K6sYxmdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_data.info()"
      ],
      "metadata": {
        "id": "_HbLzXBl-joM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_data[\"selftext\"].value_counts()"
      ],
      "metadata": {
        "id": "hICh_kw9f_Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping [deleted] and [removed] entries"
      ],
      "metadata": {
        "id": "QCqSKLar-unQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_data = reddit_data[reddit_data[\"selftext\"]!=\"[deleted]\"]\n",
        "reddit_data = reddit_data[reddit_data[\"selftext\"]!=\"[removed]\"]"
      ],
      "metadata": {
        "id": "rS2BTv72-yPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping duplicate entries"
      ],
      "metadata": {
        "id": "k5aIQncOyeRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_data = reddit_data.drop_duplicates(subset=['selftext'],keep = 'first')\n",
        "reddit_data"
      ],
      "metadata": {
        "id": "WJCeq112AXzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating post_len column to store post length"
      ],
      "metadata": {
        "id": "hdsL93OCyzpM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQdjkg7QFqPy"
      },
      "outputs": [],
      "source": [
        "reddit_data['post_len'] = reddit_data['selftext'].astype('str')\n",
        "reddit_data['post_len'] = reddit_data['post_len'].apply(lambda x : len(x))"
      ]
    }
  ]
}